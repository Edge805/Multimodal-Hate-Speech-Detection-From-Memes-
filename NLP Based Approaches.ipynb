{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7010410,"sourceType":"datasetVersion","datasetId":4030533},{"sourceId":7030885,"sourceType":"datasetVersion","datasetId":4044074},{"sourceId":7175708,"sourceType":"datasetVersion","datasetId":3950344},{"sourceId":7177586,"sourceType":"datasetVersion","datasetId":4148075},{"sourceId":7241630,"sourceType":"datasetVersion","datasetId":4057929},{"sourceId":7250674,"sourceType":"datasetVersion","datasetId":4200910},{"sourceId":7250795,"sourceType":"datasetVersion","datasetId":4200865},{"sourceId":7250824,"sourceType":"datasetVersion","datasetId":4200999},{"sourceId":7272927,"sourceType":"datasetVersion","datasetId":4017200},{"sourceId":7273420,"sourceType":"datasetVersion","datasetId":4216632},{"sourceId":7278472,"sourceType":"datasetVersion","datasetId":4092417},{"sourceId":7282702,"sourceType":"datasetVersion","datasetId":4222815},{"sourceId":7295489,"sourceType":"datasetVersion","datasetId":4032188},{"sourceId":7305441,"sourceType":"datasetVersion","datasetId":4036691},{"sourceId":7344755,"sourceType":"datasetVersion","datasetId":4264849},{"sourceId":7345943,"sourceType":"datasetVersion","datasetId":4265618}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pyspellchecker\n!pip install -q ktrain","metadata":{"execution":{"iopub.status.busy":"2024-01-05T17:47:30.586636Z","iopub.execute_input":"2024-01-05T17:47:30.587557Z","iopub.status.idle":"2024-01-05T17:48:26.720405Z","shell.execute_reply.started":"2024-01-05T17:47:30.587495Z","shell.execute_reply":"2024-01-05T17:48:26.719134Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport re\nimport string \nimport spacy\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoModel, AutoTokenizer, ViTFeatureExtractor, ViTModel\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport lightgbm as lgb\nimport warnings\nfrom PIL import Image\nfrom spellchecker import SpellChecker\nfrom tensorflow.keras import activations\n\nwarnings.filterwarnings(\"ignore\")\n\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:11:43.952350Z","iopub.execute_input":"2024-01-05T19:11:43.952743Z","iopub.status.idle":"2024-01-05T19:11:44.987256Z","shell.execute_reply.started":"2024-01-05T19:11:43.952713Z","shell.execute_reply":"2024-01-05T19:11:44.986410Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"Task1_Train = pd.read_csv(\"/kaggle/input/subtask-c-final/SubTask-C-train.csv\")\nTask1_Test = pd.read_csv(\"/kaggle/input/subtask-c/SubTask-C(indextweet)test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:11:47.262924Z","iopub.execute_input":"2024-01-05T19:11:47.263743Z","iopub.status.idle":"2024-01-05T19:11:47.312021Z","shell.execute_reply.started":"2024-01-05T19:11:47.263711Z","shell.execute_reply":"2024-01-05T19:11:47.311069Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"Task1_Train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:11:49.100097Z","iopub.execute_input":"2024-01-05T19:11:49.100496Z","iopub.status.idle":"2024-01-05T19:11:49.108869Z","shell.execute_reply.started":"2024-01-05T19:11:49.100463Z","shell.execute_reply":"2024-01-05T19:11:49.107840Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"label\n1    4328\n3    2256\n2     700\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"Task1_Train.dropna(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:11:51.350281Z","iopub.execute_input":"2024-01-05T19:11:51.350665Z","iopub.status.idle":"2024-01-05T19:11:51.357598Z","shell.execute_reply.started":"2024-01-05T19:11:51.350634Z","shell.execute_reply":"2024-01-05T19:11:51.356625Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def remove_emojis(text):\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n                               u\"\\U0001F700-\\U0001F77F\"  # Alphanumeric Supplement\n                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n                               u\"\\U000024C2-\\U0001F251\" \n                               \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef remove_punctuation(input_string):\n    translator = str.maketrans('', '', string.punctuation)\n    \n    result = input_string.translate(translator)\n    \n    return result\n\ndef remove_non_english_chars(input_string):\n    translation_table = dict.fromkeys(\n        i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('C')\n    )\n\n    result = input_string.translate(translation_table)\n\n    return result\n\ndef correct_spelling(input_text):\n    try:\n        # Create a SpellChecker object\n        spell = SpellChecker()\n\n        # Split the input text into words\n        words = input_text.split()\n\n        # Find misspelled words\n        misspelled = spell.unknown(words)\n\n        # Correct misspelled words\n        corrected_text = \" \".join(spell.correction(word) if word in misspelled else word for word in words)\n\n        return corrected_text\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return input_text\n    \nhyperlink_pattern = r'https?://\\S+|www\\.\\S+'\n\ndef PreProcessTweets(tweet):\n  tweet2 = str(tweet)\n  tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n  tweet2 = re.sub(r'#\\w+', '', tweet2)\n  tweet2 = tweet2.replace(\"LINK\",\"\")\n  tweet2 = tweet2.replace(\"&amp\",\"\") \n  tweet2 = re.sub(r'@\\w+', '', tweet2)\n  tweet2 = tweet2.replace(\"\\n\",\"\")\n  tweet2 = re.sub(r'_', ' ', tweet2)\n  tweet2 = tweet2.replace(\"UN\",\"United Nations \")\n  tweet2 = tweet2.replace(\"imglipcom\",\"\")\n  tweet2 = re.sub(hyperlink_pattern, '', tweet2)\n  tweet2 = tweet2.replace(\":\",\"\") \n  tweet2 = remove_emojis(tweet2)\n  tweet2 = remove_punctuation(tweet2)\n  tweet2 = re.sub(' +', ' ',tweet2)\n  tweet2 = tweet2.replace(\"hes\",\"he is\")\n  tweet2 = tweet2.replace(\"govt\",\"Government\")\n  #tweet2 = correct_spelling(tweet2)\n  return tweet2\n\nTask1_Train['tweet'] = Task1_Train['tweet'].apply(lambda x: PreProcessTweets(x))\nTask1_Test['tweet'] = Task1_Test['tweet'].apply(lambda x: PreProcessTweets(x))","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:11:53.406347Z","iopub.execute_input":"2024-01-05T19:11:53.406733Z","iopub.status.idle":"2024-01-05T19:11:53.820527Z","shell.execute_reply.started":"2024-01-05T19:11:53.406700Z","shell.execute_reply":"2024-01-05T19:11:53.819747Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def NERFeatureExtractor(text, nlp = nlp):\n    doc = nlp(text)\n    PersonCount = NORPCount = ORGCount = 0\n    for ent in doc.ents:\n        if ent.label_ == 'PERSON':\n            PersonCount += 1\n        elif ent.label_ == 'NORP':\n            NORPCount += 1\n        elif ent.label_ == 'ORG':\n            ORGCount += 1\n    NERFeaturesReady = {'PersonCount' : PersonCount, 'NORPCount' : NORPCount , 'ORGCount' : ORGCount}\n    return NERFeaturesReady","metadata":{"execution":{"iopub.status.busy":"2023-12-28T07:49:22.811386Z","iopub.execute_input":"2023-12-28T07:49:22.812047Z","iopub.status.idle":"2023-12-28T07:49:22.825640Z","shell.execute_reply.started":"2023-12-28T07:49:22.812002Z","shell.execute_reply":"2023-12-28T07:49:22.824162Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"Task1_Train['label'] = Task1_Train['label'].astype(str)\n\ndef ReSampler(reqClass, DataFrame, TargetClass = 'label'):\n    SubDataFrame = DataFrame[DataFrame[TargetClass] == reqClass].copy()\n    DataFrame = pd.concat([DataFrame, SubDataFrame], axis = 0)\n    del SubDataFrame\n    return DataFrame\n\nTask1_Train = ReSampler('2',Task1_Train)\nTask1_Train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:12:24.867256Z","iopub.execute_input":"2024-01-05T19:12:24.867602Z","iopub.status.idle":"2024-01-05T19:12:24.888504Z","shell.execute_reply.started":"2024-01-05T19:12:24.867575Z","shell.execute_reply":"2024-01-05T19:12:24.887475Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"label\n1    4328\n3    2256\n2    1400\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"NERFeatureExtractor('british Government msm sheer hypocrisy Out of respect you must stop strikingprotestingplaying sport GovtSystemsChangePlanetarySurvivalCitizensAssembliesOurOnlyHope')","metadata":{"execution":{"iopub.status.busy":"2023-12-26T08:19:22.604110Z","iopub.execute_input":"2023-12-26T08:19:22.604978Z","iopub.status.idle":"2023-12-26T08:19:22.633941Z","shell.execute_reply.started":"2023-12-26T08:19:22.604945Z","shell.execute_reply":"2023-12-26T08:19:22.633092Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'PersonCount': 0, 'NORPCount': 0, 'ORGCount': 1}"},"metadata":{}}]},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nTask1_Test['label'] = -1\n\nfrom transformers import pipeline\n\npipe = pipeline(\"summarization\", model=\"currentlyexhausted/flan-t5-summarizer\") \n\nTask1_Test['result'] = Task1_Test['text'].apply(pipe)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(Task1_Train)):\n    NERFeaturesReady = NERFeatureExtractor(Task1_Train['text'][i])\n    Task1_Train['PersonCount'][i] = NERFeaturesReady['PersonCount']\n    Task1_Train['NORPCount'][i] = NERFeaturesReady['NORPCount']\n    Task1_Train['ORGCount'][i] = NERFeaturesReady['ORGCount']\n\nfor i in range(len(Task1_Test)):\n    NERFeaturesReady = NERFeatureExtractor(Task1_Dev['text'][i])\n    Task1_Test['PersonCount'][i] = NERFeaturesReady['PersonCount']\n    Task1_Test['NORPCount'][i] = NERFeaturesReady['NORPCount']\n    Task1_Test['ORGCount'][i] = NERFeaturesReady['ORGCount']","metadata":{"execution":{"iopub.status.busy":"2023-12-11T17:25:51.897578Z","iopub.execute_input":"2023-12-11T17:25:51.898344Z","iopub.status.idle":"2023-12-11T17:26:15.687969Z","shell.execute_reply.started":"2023-12-11T17:25:51.898314Z","shell.execute_reply":"2023-12-11T17:26:15.687131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss(smooth=1e-5, from_logits=True):\n    def dice_loss(y_true, y_pred,):\n        y_true = K.cast(y_true, dtype=tf.float32)\n        y_pred = K.cast(y_pred, dtype=tf.float32)\n        intersection = tf.reduce_sum(y_true * y_pred)\n        sum_of_squares_pred = tf.reduce_sum(tf.square(y_pred))\n        sum_of_squares_true = tf.reduce_sum(tf.square(y_true))\n        dice = 1. - (2. * intersection + smooth) / (sum_of_squares_pred + sum_of_squares_true + smooth)\n        return dice\n    return dice_loss","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:12:54.119066Z","iopub.execute_input":"2024-01-05T19:12:54.120068Z","iopub.status.idle":"2024-01-05T19:12:54.126307Z","shell.execute_reply.started":"2024-01-05T19:12:54.120018Z","shell.execute_reply":"2024-01-05T19:12:54.125451Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def focal_loss(gamma=3, alpha=0.25, from_logits=True):\n\n    gamma = float(gamma)\n    alpha = float(alpha)\n\n    def focal_loss_fixed(y_true, y_pred):\n        epsilon = 1.e-9\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        y_pred = tf.cast(y_pred, dtype=tf.float32)\n        if from_logits:\n            y_pred = activations.softmax(y_pred)\n\n        model_out = tf.add(y_pred, epsilon)\n        ce = tf.multiply(y_true, -tf.math.log(model_out))\n        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n        reduced_fl = tf.reduce_max(fl, axis=1)\n        return tf.reduce_mean(reduced_fl)\n    return focal_loss_fixed","metadata":{"execution":{"iopub.status.busy":"2023-12-22T11:18:03.745382Z","iopub.execute_input":"2023-12-22T11:18:03.745780Z","iopub.status.idle":"2023-12-22T11:18:03.753784Z","shell.execute_reply.started":"2023-12-22T11:18:03.745751Z","shell.execute_reply":"2023-12-22T11:18:03.752737Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\n\n# Calculate the weights for each class so that we can balance the data\nweights = class_weight.compute_class_weight(class_weight = 'balanced',\n                                            classes = np.unique(Task1_Train['label']),\n                                            y = Task1_Train['label'])\nweights\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T11:22:38.804234Z","iopub.execute_input":"2023-12-14T11:22:38.804969Z","iopub.status.idle":"2023-12-14T11:22:38.823588Z","shell.execute_reply.started":"2023-12-14T11:22:38.804934Z","shell.execute_reply":"2023-12-14T11:22:38.822513Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([0.56099815, 3.46857143, 1.07624113])"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(Task1_Train['tweet'], Task1_Train['label'], test_size=0.15, random_state = 44)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:12:43.724231Z","iopub.execute_input":"2024-01-05T19:12:43.724845Z","iopub.status.idle":"2024-01-05T19:12:43.733463Z","shell.execute_reply.started":"2024-01-05T19:12:43.724805Z","shell.execute_reply":"2024-01-05T19:12:43.732332Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import ktrain\nfrom ktrain import text\n\nmodel_name = \"roberta-large\"\n\nt = text.Transformer(model_name, maxlen = 40, classes = ['1','2','3'])\ntrn = t.preprocess_train(X_train.values, y_train.values)\nval = t.preprocess_test(X_test.values, y_test.values)\n\nmodel = t.get_classifier()\n\nmodel.compile(loss = dice_loss(smooth = 1e-6), metrics = ['accuracy'], optimizer = 'adam')\n\nlearner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:23:29.681048Z","iopub.execute_input":"2024-01-05T19:23:29.681405Z","iopub.status.idle":"2024-01-05T19:23:51.535120Z","shell.execute_reply.started":"2024-01-05T19:23:29.681374Z","shell.execute_reply":"2024-01-05T19:23:51.534346Z"},"trusted":true},"execution_count":62,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03a3baae230745128bd22a998cba6bac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"819db4be54504611a84bf0515dc61b43"}},"metadata":{}},{"name":"stdout","text":"preprocessing train...\nlanguage: en\ntrain sequence lengths:\n\tmean : 18\n\t95percentile : 38\n\t99percentile : 45\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e4728e4ef34940b3ce488d5ba054dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e67cdb30de194642a326a71a21f578f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ac85238a5a4c7980c0dc1436caae0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Is Multi-Label? False\npreprocessing test...\nlanguage: en\ntest sequence lengths:\n\tmean : 18\n\t95percentile : 38\n\t99percentile : 43\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"learner.autofit(2e-5, monitor='val_loss')","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:23:54.431539Z","iopub.execute_input":"2024-01-05T19:23:54.431927Z","iopub.status.idle":"2024-01-05T19:52:48.068588Z","shell.execute_reply.started":"2024-01-05T19:23:54.431896Z","shell.execute_reply":"2024-01-05T19:52:48.067615Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"early_stopping automatically enabled at patience=5\nreduce_on_plateau automatically enabled at patience=2\n\n\nbegin training using triangular learning rate policy with max lr of 2e-05...\nEpoch 1/1024\n425/425 [==============================] - 176s 331ms/step - loss: 0.3034 - accuracy: 0.6490 - val_loss: 0.2558 - val_accuracy: 0.6694\nEpoch 2/1024\n425/425 [==============================] - 130s 307ms/step - loss: 0.2673 - accuracy: 0.6637 - val_loss: 0.2219 - val_accuracy: 0.7028\nEpoch 3/1024\n425/425 [==============================] - 130s 306ms/step - loss: 0.2465 - accuracy: 0.6846 - val_loss: 0.2138 - val_accuracy: 0.7270\nEpoch 4/1024\n425/425 [==============================] - 130s 306ms/step - loss: 0.2322 - accuracy: 0.7081 - val_loss: 0.2078 - val_accuracy: 0.7295\nEpoch 5/1024\n425/425 [==============================] - 130s 306ms/step - loss: 0.2211 - accuracy: 0.7252 - val_loss: 0.2048 - val_accuracy: 0.7295\nEpoch 6/1024\n425/425 [==============================] - 129s 304ms/step - loss: 0.2074 - accuracy: 0.7414 - val_loss: 0.2068 - val_accuracy: 0.7262\nEpoch 7/1024\n425/425 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.7554\nEpoch 00007: Reducing Max LR on Plateau: new max lr will be 1e-05 (if not early_stopping).\n425/425 [==============================] - 129s 304ms/step - loss: 0.1988 - accuracy: 0.7554 - val_loss: 0.2054 - val_accuracy: 0.7237\nEpoch 8/1024\n425/425 [==============================] - 130s 306ms/step - loss: 0.1798 - accuracy: 0.7838 - val_loss: 0.2029 - val_accuracy: 0.7387\nEpoch 9/1024\n425/425 [==============================] - 130s 305ms/step - loss: 0.1658 - accuracy: 0.8031 - val_loss: 0.2057 - val_accuracy: 0.7321\nEpoch 10/1024\n425/425 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.8196\nEpoch 00010: Reducing Max LR on Plateau: new max lr will be 5e-06 (if not early_stopping).\n425/425 [==============================] - 129s 304ms/step - loss: 0.1557 - accuracy: 0.8196 - val_loss: 0.2132 - val_accuracy: 0.7287\nEpoch 11/1024\n425/425 [==============================] - 129s 305ms/step - loss: 0.1422 - accuracy: 0.8369 - val_loss: 0.2104 - val_accuracy: 0.7379\nEpoch 12/1024\n425/425 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.8478\nEpoch 00012: Reducing Max LR on Plateau: new max lr will be 2.5e-06 (if not early_stopping).\n425/425 [==============================] - 129s 304ms/step - loss: 0.1344 - accuracy: 0.8478 - val_loss: 0.2110 - val_accuracy: 0.7421\nEpoch 13/1024\n425/425 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.8634Restoring model weights from the end of the best epoch: 8.\n425/425 [==============================] - 130s 307ms/step - loss: 0.1238 - accuracy: 0.8634 - val_loss: 0.2126 - val_accuracy: 0.7471\nEpoch 13: early stopping\nWeights from best epoch have been loaded into model.\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x79a4c0f4fd90>"},"metadata":{}}]},{"cell_type":"code","source":"import json \n\npredictor = ktrain.get_predictor(learner.model, preproc=t)\n\nwith open('submission.json', 'w') as json_file:\n    for i in range(len(Task1_Test)):\n        pred = predictor.predict(str(Task1_Test['tweet'][i]))\n        predictionsDictionary = {'index': int(Task1_Test['index'][i]), 'prediction': int(pred)}\n        json.dump(predictionsDictionary, json_file)    \n        json_file.write('\\n')      ","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:57:46.741871Z","iopub.execute_input":"2024-01-05T19:57:46.742294Z","iopub.status.idle":"2024-01-05T20:01:49.037171Z","shell.execute_reply.started":"2024-01-05T19:57:46.742261Z","shell.execute_reply":"2024-01-05T20:01:49.036129Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nResults1 = pd.read_json(\"/kaggle/input/qwqqwwqwq/submission/submission.json\", lines=True)\nResults2 = pd.read_json(\"/kaggle/input/qwqqwwqwq/submission(1)/submission.json\", lines=True)\nResults3 = pd.read_json(\"/kaggle/input/qwqqwwqwq/submission(2)/submission.json\", lines=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T16:54:22.879952Z","iopub.execute_input":"2023-12-16T16:54:22.880875Z","iopub.status.idle":"2023-12-16T16:54:22.924480Z","shell.execute_reply.started":"2023-12-16T16:54:22.880840Z","shell.execute_reply":"2023-12-16T16:54:22.923683Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"FinalPreds=[]\nfor i in range(len(Results1)):\n  preds = {'0': 0, '1': 0}\n  preds[str(Results1['prediction'][i])] +=1\n  preds[str(Results2['prediction'][i])] +=1\n  preds[str(Results3['prediction'][i])] +=1\n  # Convert the dictionary to a list of tuples.\n  list_of_tuples = list(preds.items())\n\n  # Sort the list of tuples by the value of the tuple.\n  sorted_list_of_tuples = sorted(list_of_tuples, key=lambda x: x[1])\n  # Return the first element of the sorted list.\n  key_of_largest_item = sorted_list_of_tuples[len(preds) - 1][0]\n  FinalPreds.append(int(key_of_largest_item))","metadata":{},"execution_count":null,"outputs":[]}]}
